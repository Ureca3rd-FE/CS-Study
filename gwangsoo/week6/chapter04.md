# 메인 메모리(main memory)

## 메인 메모리의 개념

메인 메모리는 **CPU가 직접 접근할 수 있는 기억장치**이다.  
프로세스가 실행되려면 프로그램이 반드시 메모리에 올라와 있어야 한다.  
주소가 할당된 일련의 바이트들로 구성되어 있으며 CPU는 레지스터가 가리키는 주소를 따라 메모리에 접근해 다음 명령어를 가져온다.

명령어 수행 중 필요한 데이터가 메모리에 없으면 먼저 그 데이터를 가져와야 하며 이 과정을 **메모리 관리 장치**가 담당한다.

## 메모리 관리 장치(MMU)

MMU는 **논리 주소를 물리 주소로 변환**해주는 하드웨어이다.  
CPU가 메모리에 접근할 때 주소 변환, 보호, 캐시 관리 등을 담당한다.

메모리는 한정되어 있으므로 사용자에게 더 많은 공간을 제공하기 위해 **가상 주소** 개념이 도입되었다.  
가상 주소는 프로그램 입장에서 보이는 주소이며 실제 데이터가 저장된 물리 주소와는 다르다.

이때 MMU가 논리 주소(가상 주소)를 실제 물리 주소로 변환해주는 역할을 수행한다.

MMU의 주요 역할은 다음과 같다.

- 논리 주소를 물리 주소로 변환
- 프로세스마다 독립된 주소 공간 제공
- 메모리 보호(허용되지 않은 접근 차단)
- 가상 메모리 관리 및 캐시 관리

MMU가 없으면 CPU가 물리 주소를 직접 다뤄야 하므로 부담이 크다.  
MMU는 사용자가 기억장소를 직접 할당하지 않아도 되도록 하며,  
프로세스 크기가 실제 메모리보다 커도 실행이 가능하도록 돕는다.

## 메모리 보호

각 프로세스는 자신만의 독립된 메모리 공간을 가져야 하며 다른 프로세스의 공간에 접근해서는 안 된다.  
이를 위해 MMU는 **base**와 **limit** 레지스터를 이용한다.

- **base 레지스터**: 메모리상의 프로세스 시작 주소
- **limit 레지스터**: 프로세스가 사용할 수 있는 메모리 크기

프로세스의 합법적인 주소 범위는 다음과 같다.

```plaintext
base ≤ x < base + limit
```

이 범위를 벗어나면 **trap**을 발생시켜 접근을 차단한다.  
안전성을 위해 base와 limit 레지스터는 **커널 모드에서만 수정 가능**하다.  
사용자 모드에서는 직접 변경할 수 없다.

## 메모리 과할당

**메모리 과할당**은 실제 물리 메모리보다 더 큰 메모리를 프로세스에 할당한 상황을 말한다.  
운영체제는 가상 메모리를 이용해 사용자가 이를 인식하지 못하게 처리한다.

그러나 실행 중 페이지 부재가 발생했을 때 모든 프레임이 사용 중이라 빈 프레임이 없다면 문제가 생긴다.

이 경우 운영체제는 빈 프레임을 확보해야 하며 다음 두 가지 방법이 있다.

1. **프로세스를 종료시켜 빈 프레임 확보**  
   사용자가 시스템의 가상 메모리 동작을 눈치챌 위험이 있어 사용하지 않는다.
2. **다른 프로세스를 일시적으로 내보내기(swap out)**  
   확보된 공간을 새 페이지를 위한 프레임으로 사용한다.

이처럼 프로세스를 교체하며 빈 공간을 확보하는 과정을 **페이지 교체**라 한다.

## 페이지 교체

페이지 교체는 **메모리 과할당이 발생했을 때 빈 프레임을 확보하는 과정**이다.

1. 프로세스 실행 중 페이지 부재 발생
2. 필요한 페이지의 위치를 디스크에서 찾음
3. 메모리에 빈 프레임이 있는지 확인
4. 빈 프레임이 있으면 그곳에 페이지를 올림
5. 빈 프레임이 없으면 희생 프레임을 정해 디스크에 저장
6. 새 페이지를 메모리에 올리고 페이지 테이블을 갱신
7. 프로세스는 중단 없이 이어서 실행

이때 사용자가 시스템의 교체 동작을 인식하지 못하도록  
**최대한 빠르게(오버헤드를 줄여서)** 처리해야 한다.

## 오버헤드 감소 방법

페이지 교체 시에는 두 번의 디스크 접근이 필요하다.  
(희생 페이지 내보내기 + 필요한 페이지 불러오기)  
이 과정이 반복되면 입출력 연산이 많아져 오버헤드가 커진다.

이를 줄이기 위한 방법은 다음과 같다.

### (1) 변경 비트 사용

각 페이지마다 변경 비트를 두어 해당 페이지가 수정되었는지 표시한다.

- **비트가 1이면**: 메모리 내용이 디스크와 다르므로 디스크에 다시 저장해야 함
- **비트가 0이면**: 수정되지 않았으므로 디스크에 쓸 필요 없음

이를 통해 불필요한 디스크 접근을 줄여 오버헤드를 절반가량 감소시킬 수 있다.

### (2) 페이지 교체 알고리즘 최적화

상황에 따라 페이지 결함이 적게 발생하도록 적절한 교체 알고리즘을 선택해야 한다.  
주요 알고리즘은 다음과 같다.

- FIFO: 먼저 들어온 페이지를 먼저 내보냄
- OPT: 앞으로 가장 오랫동안 사용되지 않을 페이지를 내보냄
- LRU: 최근에 사용하지 않은 페이지를 먼저 내보냄

## 캐시 메모리

캐시 메모리는 **CPU와 메인 메모리의 속도 차이로 인한 성능 저하를 완화**하기 위한 장치이다.  
CPU가 자주 사용하는 데이터를 빠르게 접근할 수 있도록 임시로 저장해둔다.

캐시는 플립플롭으로 구성된 SRAM으로 만들어져  
DRAM보다 빠르지만 용량은 작다.

## CPU와 기억장치의 상호작용

1. CPU가 주소를 전달
2. 캐시에서 해당 명령어가 있는지 확인
   - 있으면(**적중**) 캐시에서 바로 가져옴
   - 없으면(**실패**) 메모리에서 가져와 캐시에 저장한 뒤 CPU에 전달
3. 결과를 CPU로 전송

캐시를 적절히 활용하면 메모리 접근 시간을 크게 줄일 수 있다.  
따라서 CPU는 **어떤 데이터가 다시 필요할지 예측하는 능력**이 중요하다.

## 지역성의 원리

프로그램은 메모리를 무작위로 접근하지 않고 **특정 부분을 집중적으로 참조하는 경향**이 있다. 이를 **지역성**이라 한다.

- **시간 지역성**: 최근에 사용된 데이터가 곧 다시 사용되는 특성
- **공간 지역성**: 접근된 주소 근처의 데이터가 곧 접근되는 특성

이 원리를 활용하면 캐시의 적중률을 높일 수 있다.

## 캐싱 라인

캐시에 저장된 데이터가 많아도 목표 데이터를 찾기 위해 모두 탐색한다면 오히려 시간이 오래 걸린다.  
따라서 캐시는 **데이터와 해당 주소를 함께 묶어 저장**한다.  
이 묶음을 **캐싱 라인**이라고 한다.

캐싱 라인을 이용하면 필요한 데이터의 위치를 빠르게 찾을 수 있다.  
주로 집합(set)이나 맵(map) 형태로 관리된다.
