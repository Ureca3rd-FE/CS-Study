# 🖲️운영체제 6주차

## Chap14. 메인 메모리 (Main Memory)

### #1. 메인 메모리

#### 메인 메모리와의 동의어

- 주기억장치 (Main Memory) : CPU가 직접 접근 가능한 1차 기억장치
- 주 메모리 (Primary Memory) : 보조기억장치(HDD/SSD)와 구분하기 위해 사용하는 표현
- RAM (Random Access Memory) : 메인 메모리의 구현 형태. 전원이 꺼지면 데이터가 사라지는 휘발성 메모리

#### 개념

- CPU가 직접 접근 가능한 기억장치
- 현재 실행 중인 프로그램과 처리중인 데이터를 일시적으로 저장하는 공간
- 보조기억장치에 있는 프로그램이 주기억장치에 적재됨으로써 프로세스로 변환됨

#### 특징

1. 휘발성 메모리 (Volatile Memory) : 전원이 꺼지면 메모리 내용이 초기화됨
2. 랜덤 액세스 (Random Access) : 메모리의 모든 위치의 데이터에 동일한 시간에 접근 가능
3. 고속 데이터 처리 : 보조저장장치보다 접근속도가 더 빠름
4. 용량과 멀티태스킹 : 메모리 용량이 클수록 동시 실행이 가능한 프로그램 수가 많아짐

#### 종류

1. DRAM (Dynamic RAM)

   - 저장된 데이터가 일정시간이 지나면 사라짐 -> 일정시간마다 재생 필요
   - 집적도가 높음(용량 up) + 구조가 단순 + 가격 저렴
   - 접근 속도가 상대적으로 느림
   - 메인 메모리, 그래픽 메모리 등으로 사용

2. SRAM (Static RAM)
   - 전력이 공급되는 동안 데이터 보관 가능 -> 재생(새로고침) 필요 X
   - 집적도가 낮음(용량 down) + 가격이 비쌈 + 전력소모 많음
   - 접근 속도가 빠름
   - CPU 캐시, 레지스터 등으로 사용
3. SDRAM (Synchronous DRAM)
   - 클록틱이 발생할 때 마다 동작하는 동기식 DRAM
     - 클록 : CPU속도와 관련된 단위.
     - 클록이 일정간격(클록사이클)마다 틱을 만듬
     - 클록틱 = 틱 = 펄스 = Rising edge + Falling edge
   - 접근 속도 빠름 + 대역폭 넓음

---

### #2. 메모리 관리 장치 (MMU - Memory Management Unit)

#### 개념

- CPU가 메모리에 접근할 때 필수적으로 사용되는 하드웨어 구성 요소
- **가상 메모리 주소**(Virtual Address)를 **물리 메모리 주소**(Physical Address)로 변환하는 역할 수행
- 운영체제와 통합 : 현대 운영체제는 MMU 기능을 전제하고 동작

#### 주요 역할

1. **주소 변환 (Adress Translation)** : 가상 주소를 실제 물리 주소로 변환
2. **메모리 보호 기능**

   - 개념 : 경계/한계 레지스터를 이용하여 운영체제에서 하드웨어적으로 메모리를 보호하는 방식
   - **경계 레지스터** (boundary/base register)
     - 경계 레지스터 값 = 프로세스의 메모리 시작 주소(물리 주소)를 저장
     - CPU가 메모리에 접근 시 논리 주소에 경계 레지스터 값을 더하여 물리주소를 계산
     - 경계 레지스터보다 큰 주소에서만 접근이 일어날 수 있게함 -> 아래 영역(운영체제, 다른 프로세스 메모리)에 대한 접근을 방지
   - **한계 레지스터** (limit register)
     - 해당 프로세스가 가질 수 있는 메모리 공간 크기 (영역 끝 주소 - 영역 시작 주소)
     - CPU가 접근하려는 논리 주소가 한계 레지스터 값보다 작은지 계속해서 검사함
   - **메모리 보호 메커니즘**
     - 프로세스가 접근하려는 주소 = 논리주소
     - 주소 변환 시 물리주소로 변환 (경계 레지스터 값 + 논리주소)
     - 허용 주소 범위
     - 경계 레지스터 <= 물리주소 < 경계 레지스터 + 한계 레지스터
     - 즉, 논리주소가 한계 레지스터 범위 내인지 확인
     - 논리 주소가 한계 레지스터 값(허용 주소 범위)을 넘어서면 예외 사항 인터럽트(트랩)를 발생하는 방식으로 제한

3. **캐시 관리**
   - CPU와 메모리 사이에서 캐시 역할 담당
   - TLB에 주소 변환 정보를 저장하여, 주소 변환 작업 시 빠르게 결과를 제공
4. **페이지 테이블 및 세그먼트 테이블 관리**
   - 다양한 메모리 관리 기법을 지원
   - 페이지/세그먼트 테이블을 탐색하여 필요한 데이터를 제공
5. **멀티태스킹 및 메모리 최적화**
   - 여러 프로세스 실행 중, 각 프로세스의 메모리 공간을 명확히 분리해줌
   - 단편화 문제를 페이징/세그먼테이션으로 해결 -> 시스템 메모리 자원을 효율적으로 사용하도록 최적화 해줌

#### 동작 과정

1. CPU가 MMU에 가상 주소를 전달
2. MMU는 페이지 테이블을 탐색하여 물리 주소로 변환
3. 변환된 물리 주소로 메모리 접근
4. TLB와 캐시 메모리가 활용되어 주소변환 속도를 높임

#### 변환 참조 버퍼(TLB - Translation Lookaside Buffer)

- 개념
  - 가상 주소와 물리 주소의 변환 정보를 임시로 보관하는 하드웨어 캐시
  - 캐시로써의 특성 : CPU 속도가 메모리 접근 속도 보다 더 빠르기 때문에 이를 맞춰주는 역할을 함
- 동작 과정
  1.  CPU가 메모리 접근 시 가상 주소를 생성
  2.  MMU는 TLB에서 가상 주소 매핑을 검색
  3.  TLB에 매핑정보가 있으면 바로 변환(TLB 히트). 없으면 페이지 테이블 검색 후 TLB 갱신(TLB 미스).
  4.  변환된 주소로 실제 메모리 접근 수행

---

### #3. 메모리 과할당 (over-allocation)

#### 개념

- 가상 메모리 시스템에서 사용하는 방법
- 가상 메모리 시스템에서는 각 **프로세스**가 **실제 물리 메모리(RAM) 용량**보다 더 큰 가상 주소 공간을 할당 받을 수 있음
- 메모리 과할당 : 전체 프로세스들의 메모리 요구량이 물리 메모리의 총 용량을 초과하는 상황

#### 특징

- 가상 메모리 전체 요구량이 커지더라도 페이지 교체, 스와핑을 통해 필요한 부분만 물리 메모리에 적재하는 방식으로 진행함
- 물리 메모리(RAM) 외에도 보조 기억장치(HDD/SSD)를 메모리처럼 활용하기 때문에, 실제 물리 메모리 용량과 관계없이 더 큰 메모리를 할당할 수 있음

#### 문제점

- 메모리 과할당이 발생 시 가상 메모리 기법을 통해 임시적으로 해결
- 가상 메모리 기법 : 보조 기억장치로 스왑인/스왑아웃
- 보조 기억장치로의 접근은 RAM보다 느림 -> 시스템 전체가 느려져 **프로세스 응답이 지연**됨
- 이는 **프로세스 강제 종료**, **시스템 불안정**으로 이어질 수 있으므로 해결 방법이 필요함

#### 해결 방법

1. 가상 메모리 기법
   - 종류
     - 페이징 : 프로세스를 페이지로 쪼개어 필요할 때만 메모리에 적재하는 방식 (나머지 페이지는 디스크-보조기억장치에 저장)
     - 스왑핑 : 프로세스 전체/일부를 디스크로 내렸다가 메모리로 올리는 방식
   - 한계 : 이는 임시방편에 해당. 근본적인 문제를 해결해주지 못함
2. 메모리 관리 최적화
   - 압축 : 빈공간을 모아 연속적인 큰 공간을 만듬
   - 단편화 해결 : 압축을 비롯한 분할 방식 개선, 동적 메모리 관리 등의 전략
   - 의의 : 실제로 사용 가능한 용량을 극대화하여 예방
3. 하드웨어적 해결
   - 물리 메모리(RAM) 증설
   - 의의 : 자원 자체를 증가시켜 근본적인 원인을 제거
4. 소프트웨어적 해결
   - 불필요한 프로세스 종료 : 사용하지 않는 프로그램, 백그라운드 프로세스를 종료하여 메모리 요구 자체를 줄임
   - 메모리 효율화 프로그래밍 : 재사용, 적절한 해제 등을 통해 코드 차원에서 메모리 활용 효율을 높임
   - 의의 : 근본 원인 차원에서 예방

---

### #4. 캐시 메모리

#### 개념

- CPU와 메인메모리(RAM) 간의 속도 차이를 완화하여 시스템 성능을 높여주는 고속 임시 저장 공간
- CPU는 캐시에 먼저 접근하고, 원하는 데이터가 없을 때 메인 메모리에 접근함
- 캐시 히트 : 해당 캐시에 원하는 데이터가 있음 -> 바로 사용
- 캐시 미스 : 해당 캐시에 원하는 데이터가 없음 -> 메인 메모리로 감

#### 특징

- 캐시(SRAM)은 메인 메모리(DRAM)보다 빠른 속도로 동작 -> 병목 현상 완화
- 저장 용량은 작음 + 자주 참조되는 데이터를 효율적으로 관리
- L1/L2/L3 등의 여러 계층으로 구성
  - L1 캐시 : CPU 코어 내부에 존재. 명령어 캐시/데이터 캐시로 분리. 가장 빠름
  - L2 캐시 : CPU 내부 OR 바로 외부에 존재. L1에 없는 데이터 저장 (보조 저장 역할).
  - L3 캐시 : 모든 CPU 코어가 공유 하는 구조. L1, L2에 없는 데이터 저장 (보완 엔진 역할).

#### 지역성 (Locality)

- 개념 : 기억 장치에 접근하는 패턴이 메모리의 특정 영역에 집중되는 성질
- 종류
  - 시간적 지역성 (Temporal locality) : 한 번 참조된 데이터가 가까운 시간 내에 다시 참조될 가능성이 높음
  - 공간적 지역성 (Spatioal locality) : 참조된 데이터의 근처 주소들도 이어서 접근될 가능성이 높음

#### 캐시 라인 (Cache Line)

- 개념 : 캐시와 메인 메모리 사이에서 데이터를 주고받는 최소 단위
- 종류 : 현대 시스템에서는 32~128 바이트를 사용. (64바이트가 표준)
- 동작 방식
  1.  CPU가 메모리 주소 참조 시, 그 주소가 포함된 캐시 라인 전체가 캐시로 로드
  2.  CPU는 해당 캐시 라인 내의 데이터에 대해 메모리 접근 없이 처리 가능
  3.  캐시에 적재되는 자료 구조는 **캐시 매핑 방식**(직접 매핑, 연관 매핑, 집합 연관 매핑)에 따라 결정됨
