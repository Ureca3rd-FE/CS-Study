# 10주차 🛜네트워크

## Chap03. 로드 밸런싱 (Load Balancing)

### #1. 로드 밸런싱이란?

#### 스케일 업 & 스케일 아웃

- **스케일 업 (scale up)**
  - 개념
    - 한 대의 서버 성능을 높이는 방식
    - CPU, RAM, 디스크 등 하드웨어를 업그레이드하여 처리량 증가
  - 특징
    - 구조 변경 없음
    - 한계가 빠르게 옴 (하드웨어의 물리적 한계 존재)
    - 비용이 비쌈
    - 장애 시 전체가 다운됨 -> 단일 장애 지점(SPOF-Single Point Of Failure) 문제
- **스케일 아웃 (scale out)**
  - 개념
    - 서버 대수를 여러 대로 늘리는 방식
    - 처리해야할 트래픽 양을 여러 서버가 나눠서 처리
  - 특징
    - 무한대에 가까운 확장 가능
    - 특정 서버 장애 시 다른 서버로 트래픽을 넘겨 서비스 지속
    - 구조가 복잡해짐 -> 서버 간 트래픽 분배 방식이 필요

#### 로드 밸런싱 (Load Balancing)

- **개념**
  - 여러 서버로 들어오는 트래픽을 균등하게 분배하여 서버 과부하를 방지하는 기술
  - 단일 서버에 부하가 몰려 장애가 발생하는 것을 막아 서비스의 안정성을 높이는 역할
- **목적**
  1. **성능 향상**
     - 여러 서버가 요청을 나눠 처리함 -> 처리량 증가
  2. **가용성(Availability) 향상**
     - 특정 서버가 장애여도 다른 서버가 서비스 지속
  3. **확장성(Scalability) 확보**
     - 서버 증설이 용이 -> 트래픽 증가에 대응이 쉬움
- **위치**
  - 클라이언트와 서버 사이에 위치
  - 요청을 대신 받아 적절한 서버로 전달

#### 로드 밸런서 (Load Balancer)

- **개념**
  - 클라이언트 요청을 받고
  - 서버들의 상태를 확인(헬스 체크)한 뒤
  - 적절한 서버에게 분배
- **종류**
  - L4 로드 밸런서: TCP/UDP 기반 분배
  - L7 로드 밸런서: HTTP/HTTPS 기반 분배

---

### #2. 로드 밸런서의 종류

#### L4 로드 밸런서 (Transport Layer - 4계층)

- **개념**

  - IP/포트 정보를 기반으로 트래픽을 분배하는 전송 계층 로드 밸런서

- **특징**

  1. TCP/UDP 포트, IP 주소를 기반으로 트래픽 분해
     - 패킷의 L3/L4 헤더 정보에 따라 서버 선택
     - L3 정보: "Src IP", "Dst IP"
     - L4 정보: "Src Port", "Dst Port"
  2. 패킷 내용(payload)을 확인하지 않음
     - HTTP 헤더, URI, 쿠키 등은 보지 않음
     - 매우 빠름 + 지연 거의 없음
  3. 전송 계층에서 라우팅
     - 하나의 TCP 연결은 동일 서버에 유지되는 세션 기반 분배
  4. 대량 트래픽 처리에 적합 (L7 대비 비용 저렴)

- **장점**

  - 초고속 처리
  - CPU 부하 거의 없음
  - 단순하고 효율적

- **단점**

  - URI, 쿠키, 헤더 기반 라우팅 불가
  - 애플리케이션 로직 반영 불가

- **예시**
  - **AWS NLB** (Network Load Balancer): AWS의 고성능 L4 로드 밸런서로, 초당 수백만 요청 처리에 최적화
  - **Linux LVS** (IPVS 기반 커널 레벨 L4 LB): 리눅스 커널에서 동작하는 고성능 L4 로드 밸런싱 프레임워크
  - **F5 LTM 일부**: 네트워크 장비 형태의 엔터프라이즈급 L4/L7 로드 밸런서

#### L7 로드 밸런서 (Application Layer - 7계층)

- **개념**

  - HTTP/HTTPS 요청의 내용(URI, 헤더, 쿠키 등)을 분석해 지능적으로 분배하는 응용 계층 로드 밸런서

- **특징**

  1. HTTP, HTTPS 프로토콜 내용을 확인하고 라우팅
     - URI(Path), Host, Header, Method, QueryString 분석 가능
  2. 애플리케이션 레벨 로직 기반 분배 가능
     - URI, 쿠키, 헤더, 메서드 등 분석 가능
     - 예시
       - 로그인 된 사용자만 특정 서버로 보냄
       - /api -> 서버1
       - /image -> 서버2
  3. 세션 기반 라우팅 가능 및 콘텐츠 기반 라우팅 가능
     - **세션 기반 라우팅 (Sticky Session)**: 같은 사용자의 요청을 항상 같은 서버로 보내는 라우팅 방식
     - **콘텐츠 기반 라우팅 (Content-Based Routing)**: 요청 내용을 기준으로 적합한 서버를 선택하는 방식
  4. L4 보다 비용, 리소스를 더 소모함 (for HTTP 헤더 및 요청 내용 파싱)

- **장점**

  - 가장 유연하고 지능적인 라우팅 가능
  - 특정 URI, 특정 사용자, 특정 헤더 기반의 고급 분배
  - SSL 오프로드(HTTPS 암복호화)를 LB에서 처리 가능

- **단점**

  - L4 대비 처리량 낮음
  - 비용 높음 (특히 클라우드에서)
  - 패킷 분석 때문에 CPU 사용량 증가

- **예시**
  - **AWS ALB** (Application Load Balancer): AWS의 L7 로드 밸런서로, HTTP/HTTPS 기반 고급 라우팅 기능을 제공
  - **Nginx**: 웹 서버 + 리버스 프록시 + L7 로드 밸런싱 기능을 제공하는 오픈소스 서버
  - **HAProxy**: 고성능·고가용성에 특화된 L4/L7 로드 밸런서 오픈소스 솔루션

---

### #3. 로드 밸런서가 서버를 선택하는 방식 (스케줄링 알고리즘)

#### 1. 라운드 로빈 (Round Robin)

- **개념**

  - 서버 목록을 순서대로 돌아가며 1개씩 요청을 분배
    - 예시: `S1 -> S2 -> S3 -> S1 -> S2 -> S3 -> ...`
  - 가장 단순하고 널리 사용됨

- **특징**

  - 서버의 현재 부하를 고려하지 않음 (순서 기반 분배)
  - "서버 성능이 모두 동일"할 때 효과적

- **사용 예시**
  - 정적 리소스 서버
  - 동일한 스펙의 서버 여러 대 있을 때

![RR](./assets/rr.png)

#### 2. 가중 라운드 로빈 (Weighted Round Robin)

- **개념**

  - 서버별 성능 차이를 반영하기 위해 가중치 부여
  - "더 높은 가중치를 가진 서버에 더 많은 트래픽"을 분배

- **특징**

  - 서버 스펙이 서로 다를 때 유용
  - 예시
    - 서버 A의 weight: 3
    - 서버 B의 weight: 1
    - A가 B보다 3배 더 자주 선택됨

- **사용 예시**
  - 일부 서버만 더 좋은 스펙일 때
  - API 서버가 여러 스펙으로 구성될 때

![WRR](./assets/wrr.png)

#### 3. 최소 연결 (Least Connection)

- **개념**

  - 현재 연결 수가 가장 적은 서버에 분배
  - "지금 가장 한가한 서버를 찾는다"는 개념

- **특징**

  - 서버 부하를 실시간으로 고려하는 동적 알고리즘
  - 요청 처리 시간이 서버별로 큰 차이가 있을 때 효율적
  - 장기 연결(WebSocket, DB 연결)에도 유리 -> **연결 유지 시간이 긴 서비스**에 최적화

- **사용 예시**
  - 애플리케이션 서버 (API 서버) -> 요청 처리 시간이 다양함
  - 요청마다 처리 시간이 다른 서비스 (예: AI interface, DB heavy API)
  - WebSocket 서버

![LS](./assets/ls.png)

#### 4. 최소 응답 시간 (Least Response Time)

- **개념**

  - 최근 응답 지연 시간이 가장 짧은 서버 선택
  - 서버별 평균 응답시간(RTT) + 현재 연결 수를 기반으로 점수 계산
  - 가장 빠르게 응답할 수 있는 서버로 라우팅

- **특징**
  - 서버가 실제로 얼마나 빠르게 요청을 처리했는지 기반
  - 가장 지능적인 동적 알고리즘
  - 트래픽 편중 확률 낮음
  - RTT 기반 라우팅
    - L7 로드 밸런서에서 가능
    - L4에서는 RTT 기반 판단이 불가능
- **사용 예시**
  - 응답 시간 차이가 큰 API 서버
  - 일정하지 않은 부하가 들어오는 고변동 트래픽 환경

![LRT](./assets/lrt.png)

#### 5. IP Hash (Client Hash)

- **개념**

  - 클라이언트의 고유 값(IP, Cookie, UserID 등)을 해싱하여 항상 같은 서버로 보내는 방식
  - 세션 일관성 제공 (Session Affinity)

- **특징**

  - 세션 유지가 필요할 때 유리
  - 서버가 추가/삭제되면 해시 재계산 수행 -> Consistent Hashing 활용 시 해결
  - L4는 IP 기반 해시만 가능
  - L7은 IP, Cookie, Header, UserID 등 다양한 값 기반 해싱 가능

- **사용 예시**
  - 세션이 로컬 메모리에 저장되는 환경 (Sticky Session)
  - 로그인 상태 유지가 중요한 서비스

![IH](./assets/ih.png)

---

### #4. 헬스 체크 (Health Check)

#### 개념

- 로드 밸런서가 백엔드 서버의 상태를 주기적으로 검사하는 기능
- 죽은 서버로 트래픽이 가지 않도록 방지
- 서버 가용성(Availability) 유지에 필수!

#### 1. L4 Health Check (TCP 기반 검사)

- **동작 방식**

  - LB->서버로 TCP SYN 패킷을 전송 포트가 열려 있는지 확인
  - 서버가 SYN-ACK을 돌려주면 정상, 응답이 없으면 비정상

- **특징**

  - 빠르고 비용 적음
  - L4 체크는 네트워크/포트 레벨 정상 여부만 확인 가능
  - 애플리케이션 자체의 정상 여부는 알 수 없음

- **정상 판단 기준**

  - 포트 열려있음
  - TCP 연결이 정상적으로 설정되는 경우

- **비정상 판단 사례**

  1. 포트가 닫혀있는 걸로 판단 (TCP 응답이 안옴)
  2. 서버(App)는 죽었지만 OS는 포트 LISTEN 상태인 경우
  3. 포트가 열려있지만 응답이 너무 느림 (Timeout 처리)
  4. 방화벽이 SYN은 통과시켰지만 ACK에서 실패

- **L4 헬스체크는 과정은 3-way handshake 방식일까?**
  - 구현체 마다 헬스 체크 방식이 다름
    - 원칙적으로는 3-way handshake 수준의 TCP 연결 검사를 사용:
    - SYN -> SYN/ACK -> ACK 까지 확인하는 경우: 일반적으로는 3-way handshake 수준의 TCP 연결 검사 사용
    - SYN -> SYN/ACK 까지만 확인하는 경우: TCP 포트가 정상적으로 응답하는지만 보면되므로 마지막 ACK확인은 안하는 경우도 존재
  - 예시
    - AWS NLB: TCP Health Check -> 완전한 TCP 연결 (3-way handshake)
    - LVS: 옵션에 따라 다름. 3-way handshake 모드와 SYN->SYN/ACK만 확인하고 끝내는 모드 존재

#### 2. L7 Health Check (HTTP/HTTPS 요청 기반 검사)

- **동작 방식**

  1. LB가 지정된 경로로 HTTP GET 요청을 보냄

  - 지정된 경로(`/health`, `/status`, `/ping` 등)는 LB가 애플리케이션 정상여부를 판단하기 위해 만든 전용 엔드포인트

  2. 응답 코드(200 OK)를 확인 -> 애플리케이션 처리가 가능하다고 판단

- **특징**

  - HTTP 응답까지 확인 -> 애플리케이션 레벨 상태 확인 가능
  - 더 정확하지만 L4보다 비용/부하가 높음

- 정상 판단 사례

  1. 응답 코드 -> `200 OK`
  2. JSON 응답 포함 -> `200 + {"status":"UP"}`
  3. 문자열에 OK가 포함된 경우 (Nginx) -> `200 + OK 문자열`

- 비정상 판단 사례
  1. 응답 코드 != 200 OK
     - 500: 서버 오류, 애플리케이션 자체에 문제가 있는 경우
     - 503: 서버 과부하, 작업 중, 준비되지 않은 상태
     - 404: 해당 경로가 없거나 서버 라우팅 문제인 경우
  2. Timeout: 애플리케이션이 응답 안함

#### 결과

- 정상: 서버 리스트에 포함
- 비정상: 서버 리스트에서 제외

---

### #5. 로드 밸런서 장애 대비

#### 개념

- 로드 밸런서 자체에 장애가 생기면 서비스 전체가 다운됨
  - 로드 밸런서가 이중화를 하지 않은 상태인 경우
  - 로드 밸런서도 단일 장애 지점(SPOF)이 될 수 있음
- 로드 밸런서 또한 이중화(HA - High Availability)가 필요
  - LB를 여러대 둠
  - LB 장애 시 자동 전환 (Failover) 수행

#### 종류

1. **Active-Standby 구조**

   - 개념

     - LB1: Active -> 실제 트래픽 처리
     - LB2: Standby -> 대기 상태, Active 상태 모니터링
     - Active 장애 시 Standby가 자동 승격 (Failover)

   - 특징

     - 구조 간단 (일반적으로 2대 - 최소 이중화: Active/Standby)
     - 장애 전환 속도 빠름
     - 단점: Standby는 트래픽을 처리하지 않아 리소스 활용 효율 낮음
     - VIP 기술을 사용하는 경우와 그렇지 않은 경우가 있음
       - VIP 사용 X: Failover 시 IP가 바뀜
       - VIP 사용 O: Failover 시 IP가 안바뀜

   - VIP(Virtual IP) 기반 장애 전환

     - 개념

       - Active-Standby를 구현하는 기술 중 하나
       - 여러 LB가 하나의 가상 IP를 공유
       - Active LB만 VIP를 할당받아 트래픽 처리
       - Active가 죽으면 Standby가 VIP를 가져와 서비스 연속성 확보

     - 특징

       - VIP는 하나 (다중 VIP사용하는 구조도 존재하긴 함)
       - VIP를 가지는 LB가 Active

2. **Active-Active 구조**

   - 개념

     - LB 여러 대가 동시에 트래픽 처리
     - LB들이 풀(pool)을 이루며 부하 분산
     - Active LB 중 하나가 죽어도 서비스 유지

   - 대표적 구성

     - DNS Load Balancing + 여러 대의 L7 LB

       - DNS가 여러 LB의 IP를 라운드로빈,가중치 방식으로 반환
       - 예시: Route53 -> 여러 ALB로 트래픽 분산

     - Anycast IP 기반 L4 LB 다중 운영
       - 여러 지역/여러 노드에 동일한 IP(Anycast IP)를 가진 L4 LB가 동시에 활성 상태로 서비스하는 구조
       - 클라이언트는 라우팅 경로상 가장 가까운 LB로 자동 접속
       - 예시: 서울 LB 장애 시 가장 가까운 지역의 LB(도쿄 LB)로 Failover
         - 192.0.2.1 (Anycast IP)
         - 서울 LB → 192.0.2.1
         - 도쿄 LB → 192.0.2.1
         - 미국 LB → 192.0.2.1

   - 특징

     - 수평 확장 용이
     - LB 장애 시 자동으로 나머지가 처리 -> 서비스 영향 적음
     - 단점: 구조 복잡, 비용 증가

---

### 퀴즈
#### 1번. Sticky Session이란, 사용자가 최초로 연결된 서버로 이후 요청도 계속 전달되도록 “세션 기반으로 라우팅을 고정하는 방식”이다. Sticky Session은 세션 기반 라우팅인데, 이 기능을 지원할 수 있는 로드 밸런서는 L4 LB와 L7 LB 중 어느 것인가? 그 이유도 설명하시오.

- 힌트: Sticky Session이 가능하려면?
    - 사용자가 누구인지
    - 어떤 세션인지 알아야 함

- 답: L7 LB. 애플리케이션 레벨의 데이터를 읽을 수 있어야 함.

#### 2번. 동영상 스트리밍 플랫폼 서버가 있다. 사용자는 스트리밍을 시작하면 서버와의 연결이 30분~2시간 동안 유지된다. 대부분의 부하는 “연결 유지 수”에 따라 갈린다. 로드 밸런서가 서버를 선택하는 방식 중 가장 알맞은 것을 고른다면?

1. 라운드 로빈
2. 가중 라운드 로빈
3. 최소 연결
4. 최소 응답 시간
5. IP 해시

- 답: 3번 
    - 사용자와 서버가 장시간 연결되는 서비스에서는 서버 부하가 현재 유지 중인 연결 수에 의해 결정됨
    - 응답 시간에 중점을 둔 것이 아니라, 서버의 안정성의 중점을 두는 상황이기 때문
    - 서버1과 서버2가 있는데 서버1에는 100개가 연결, 서버2는 50개가 연결됨
    - 서버1의 응답 속도가 더 빠르다고 해서 서버1에 연결을 추가하게 된다면, 서버1에 부하가 걸리게 되고 이는 서비스 안정성에 문제를 야기할 수 있음 